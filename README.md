# Extractive-Text-Summarization-Using-BiLSTM-and-Meta-Learning
In modern times, the internet is flooded with vast amounts of textual information, posing  a challenge for consumers to read and comprehend effectively within a limited timeframe. Extractive text summarization
offers a technique to address this issue by selecting the most relevant and informative sentences from the original text to create a summary. There are various pre-trained language models with good performance. However, they may have limitations, such as the need for large training datasets, and the lack of interpretability or transparency of the model, especially considering that different topics may require distinct summarization techniques. To overcome these challenges, we implemented a Bidirectional Long Short-Term Memory (BiLSTM) based model, and Model Agnostic Meta-Learning (MAML) algorithm was utilized for training the deep learning model. Subsequently, various interpretability techniques such as linear regression, decision trees, and input modification are applied to gain insights into the modelâ€™s decision-making process. To assess the effectiveness of our approach, we compared it to other popular pre-trained models such as BERT, GPT-2, and XLNET. This model provides ROUGE-1 F1 score of 0.6385 and ROUGE-L F1 score of 0.4265. 
